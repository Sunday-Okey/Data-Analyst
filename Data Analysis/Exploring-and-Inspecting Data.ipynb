{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c95d5d5",
   "metadata": {},
   "source": [
    "# Exploring and Inspecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b9fae",
   "metadata": {},
   "source": [
    "### Lesson Overview\n",
    "Now with a better grasp of Jupyter Notebooks, we can begin our journey of digging into datasets to investigate what intrigues us. It is typically recommended when starting to focus on several important topics when inspecting a new dataset. We also need to understand how to read and write our data to move forward with the data analysis process. With these foundational skills in place, we can gradually develop our intuition about how to explore our data.\n",
    "\n",
    "In this lesson, you will be:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66024d1a",
   "metadata": {},
   "source": [
    "- Forming and asking questions with data\n",
    "- Defining data wrangling and EDA\n",
    "- Gathering data\n",
    "- Reading CSV files with pandas\n",
    "- Using pandas to inspect and assess data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eba7e2",
   "metadata": {},
   "source": [
    "## Asking Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0290c60c",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=0LexLA1Hres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d7f785",
   "metadata": {},
   "source": [
    "The first step of the data analysis process is asking questions. Sometimes we ask questions first and get our data later and other times we get the data first and ask questions based on it. Here, we will practice asking questions with a real dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ade826f",
   "metadata": {},
   "source": [
    "### Dataset information\n",
    "For more information from the dataset source, visit UCI's ML repository(opens in a new tab). We will dive into additional details about this dataset on the next page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7975d586",
   "metadata": {},
   "source": [
    "pd.read_csv\n",
    "\n",
    "As shown in the video, you can use df = pd.read_csv('some_csv_file.csv') (where pd is the shorthand for pandas) with the related filename to read a CSV file into a pandas dataframe. We'll come back to CSV files shortly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536b586f",
   "metadata": {},
   "source": [
    "## Questions for a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0bc36f",
   "metadata": {},
   "source": [
    "Breast Cancer Wisconsin (Diagnostic) Dataset from UCI Machine Learning Lab\n",
    "(The dataset is included in the workspace here for you as \"cancer_data.csv.\" If you're interested, you can explore it further here, on Kaggle(opens in a new tab) or UCI's ML repository(opens in a new tab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe9ca2c",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "\n",
    "- ID number\n",
    "- Diagnosis (M = malignant, B = benign)\n",
    "- 30 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee813fb",
   "metadata": {},
   "source": [
    "The following ten features are computed for each cell nucleus. For each of these ten features, a column is created for the mean, standard error, and max value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01082a1e",
   "metadata": {},
   "source": [
    "Feature\tDescription\n",
    "Radius\tMean of distances from center to points on the perimeter\n",
    "Texture\tStandard deviation of gray-scale values\n",
    "Perimeter\t\n",
    "Area\t\n",
    "Smoothness\tLocal variation in radius lengths\n",
    "Compactness\tPerimeter2 / Area - 1.0\n",
    "Concavity\tSeverity of concave portions of the contour\n",
    "Concave Points\tNumber of concave portions of the contour\n",
    "Symmetry\t\n",
    "Fractal Dimension\t\"Coastline approximation\" - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502908ad",
   "metadata": {},
   "source": [
    "Let's use pandas to take a look at the data! Run the cells in the Jupyter Notebook below. What are good questions you can ask based on this information?\n",
    "\n",
    "Work through the workspace notebook below to prepare for answering the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e15b93",
   "metadata": {},
   "source": [
    "## Data Wrangling and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4149cb29",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=EQXfxbUup0o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f93af4f",
   "metadata": {},
   "source": [
    "- Defining terms\n",
    "\n",
    "Wrangling and EDA (exploratory data analysis) are sometimes used synonymously because their purposes often overlap. However, in this course, we will use the following to define our terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c97a756",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "exploring and augmenting data to maximize the potential of analysis, visualizations, and models; for example, engineering new features and removing outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b23ce0",
   "metadata": {},
   "source": [
    "## Wrangling\n",
    "\n",
    "gathering, assessing, and cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6686eee2",
   "metadata": {},
   "source": [
    "There are plenty of examples of data wrangling and EDA concepts within the industry. For example, you may need to clean large amounts of data before entering it into a database because some fields you collected on a web page are empty. Or augment the data by normalizing and correcting any spelling errors that the user may have put into a field by mistake.\n",
    "\n",
    "Wrangling and EDA are important not just for preparing for data analysis but afterward as well. Visualizations, for example, help communicate any findings you have, which we will detail later in this course.\n",
    "\n",
    "If you would like to learn more about what happens in practice, check out these examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e386021c",
   "metadata": {},
   "source": [
    "## Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2156ba7f",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=4bwJp623Foc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658df5ba",
   "metadata": {},
   "source": [
    "Data acquisition can happen in a number of ways:\n",
    "\n",
    "- Downloading files that are readily available\n",
    "- Getting data from an API or web scraping\n",
    "- Pulling data from existing databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db1bac4",
   "metadata": {},
   "source": [
    "There may also be a need to combine data from multiple different formats.\n",
    "\n",
    "- Defining terms\n",
    "- CSV (comma separated values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428efaa5",
   "metadata": {},
   "source": [
    "a text file with a tabular structure that holds only raw data. It is easy to process manually using code such as Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be939e",
   "metadata": {},
   "source": [
    "An example of what a CSV file would look like if you opened it in a text editor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d4c9b6",
   "metadata": {},
   "source": [
    "header_name1,header_name2,header_name3\n",
    "one,14,town\n",
    "five,42,city\n",
    "ten,30,town"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feedcb39",
   "metadata": {},
   "source": [
    "## Reading CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585d389b",
   "metadata": {},
   "source": [
    "Continuing with the practice of gathering data for analysis, we're introducing several new datasets for you to read into DataFrames. You've seen .read_csv() before, but now let's understand its functionality better.\n",
    "\n",
    "The .read_csv() method will read any CSV-type file and transform it into a pandas DataFrame. This is incredibly useful, as you can leverage all the power of pandas on the data from the CSV. For comparison, Excel is limit bound(opens in a new tab) by the number of rows it can handle, which makes analyzing large datasets difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8425fa6",
   "metadata": {},
   "source": [
    "Five major parameters from .read_csv() are the focus of this page:\n",
    "\n",
    "- filepath = file path of the CSV being read\n",
    "- sep = separator, typically ,\n",
    "- header = header of the CSV file (there can be a header or not)\n",
    "- index_col = which columns should be defined as the index, or create a new index numerically\n",
    "- names = custom labels for each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9539352f",
   "metadata": {},
   "source": [
    "CSV files are not always the same, so understanding the differences and flexibility of pandas' .read_csv() method is critical. You'll also be learning how to manage DataFrame headers and indices, as well as outputting modified DataFrames into new CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ce114e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
